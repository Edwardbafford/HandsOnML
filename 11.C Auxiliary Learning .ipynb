{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Learning \n",
    "\n",
    "Train a tensorflow network to learn to recognize if two MNIST digits are the same. Then retrain on minimal data to recognize all nine digits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "p = np.random.permutation(len(y_train))\n",
    "\n",
    "x_reg, y_reg = x_train[p][:5000], y_train[p][:5000]\n",
    "x_aux, y_aux = x_train[p][5000:], y_train[p][5000:]\n",
    "\n",
    "x_reg, x_aux, x_test = x_reg/255.0, x_aux/255.0, x_test/255.0\n",
    "x_reg, x_aux, x_test = x_reg.reshape(-1,28*28), x_aux.reshape(-1,28*28), x_test.reshape(-1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting mini batches of matching and non matching images\n",
    "\n",
    "def aux_mini_batch(x_aux, y_aux, size):\n",
    "    p1 = np.random.permutation(len(y_aux))\n",
    "    p2 = np.random.permutation(len(y_aux))\n",
    "    \n",
    "    s_left = x_aux[p1][y_aux[p1] == y_aux[p2]][:size]\n",
    "    s_right = x_aux[p2][y_aux[p1] == y_aux[p2]][:size]\n",
    "    same = np.ones(size)\n",
    "    \n",
    "    d_left = x_aux[p1][y_aux[p1] != y_aux[p2]][:size]\n",
    "    d_right = x_aux[p2][y_aux[p1] != y_aux[p2]][:size]\n",
    "    diff = np.zeros(size)\n",
    "\n",
    "    left = np.concatenate((s_left, d_left), axis=0)\n",
    "    right = np.concatenate((s_right, d_right), axis=0)\n",
    "    labels = np.concatenate((same, diff))\n",
    "    \n",
    "    pf = np.random.permutation(len(labels))\n",
    "    \n",
    "    return left[pf], right[pf], labels[pf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left, right, same = aux_mini_batch(x_aux, y_aux, 100)\n",
    "same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the computational graph\n",
    "# Two networks, each one takes an image and matches i\n",
    "\n",
    "from tensorflow.contrib.layers import fully_connected \n",
    "from tensorflow.contrib.layers import batch_norm\n",
    "from tensorflow.contrib.layers import dropout\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "is_training = tf.placeholder(tf.bool, shape=(), name='is_training')\n",
    "\n",
    "# Inputs for training\n",
    "X = tf.placeholder(tf.float32, shape=(None,28*28), name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')\n",
    "X_drop = dropout(X,.5, is_training=is_training)\n",
    "\n",
    "# Nueral Network layers\n",
    "with tf.name_scope('network'):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    bn_params = {'is_training':is_training, 'decay':0.99, 'updates_collections':None}\n",
    "    \n",
    "    with tf.contrib.framework.arg_scope([fully_connected], weights_initializer=he_init, activation_fn=tf.nn.elu, \n",
    "                                        normalizer_fn=batch_norm, normalizer_params=bn_params):\n",
    "        h1 = dropout(fully_connected(X_drop, 100, scope='h1'))\n",
    "        h2 = dropout(fully_connected(h1, 100, scope='h2'))\n",
    "        h3 = dropout(fully_connected(h2, 100, scope='h3'))\n",
    "        h4 = dropout(fully_connected(h3, 100, scope='h4'))\n",
    "        h5 = dropout(fully_connected(h4, 100, scope='h5'))\n",
    "        output = fully_connected(h5, 5, scope='output', activation_fn=None)\n",
    "\n",
    "# Loss from Network\n",
    "with tf.name_scope('loss'):\n",
    "    x_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=output)\n",
    "    loss = tf.reduce_mean(x_entropy, name='loss')\n",
    "\n",
    "# SGD\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train = optimizer.minimize(loss)\n",
    "    \n",
    "# Evaluation of performance\n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(output, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
