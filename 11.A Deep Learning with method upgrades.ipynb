{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with upgrades\n",
    "\n",
    "Use the TensorFlow framework to create a deep nueral network - this time utilizing the most powerful features currently known for the model. Again we use the train the model on the MNIST (0-4 only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#Filter 0-4 for auxilary training in later notebook\n",
    "x_train, y_train = x_train[y_train <= 4], y_train[y_train <= 4]\n",
    "x_test, y_test = x_test[y_test <= 4], y_test[y_test <= 4]\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train, x_test = x_train.reshape(-1,28*28), x_test.reshape(-1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create method for getting batches for training\n",
    "\n",
    "class mini_batches:\n",
    "    \n",
    "    def __init__(self, x, y, size):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.size = size\n",
    "        self.index = 0\n",
    "    \n",
    "    def next_batch(self):\n",
    "        if self.index + self.size >= len(self.x):            \n",
    "            batch_x = self.x[self.index:]\n",
    "            batch_y = self.y[self.index:]\n",
    "            self.index = 0\n",
    "            return batch_x, batch_y\n",
    "        \n",
    "        batch_x = self.x[self.index:self.index + self.size]\n",
    "        batch_y = self.y[self.index:self.index + self.size]\n",
    "        self.index = self.index + self.size\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the computational graph\n",
    "\n",
    "from tensorflow.contrib.layers import fully_connected \n",
    "from tensorflow.contrib.layers import batch_norm\n",
    "from tensorflow.contrib.layers import dropout\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "is_training = tf.placeholder(tf.bool, shape=(), name='is_training')\n",
    "\n",
    "# Inputs for training\n",
    "X = tf.placeholder(tf.float32, shape=(None,28*28), name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')\n",
    "X_drop = dropout(X,.5, is_training=is_training)\n",
    "\n",
    "# Nueral Network layers\n",
    "with tf.name_scope('network'):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    bn_params = {'is_training':is_training, 'decay':0.99, 'updates_collections':None}\n",
    "    \n",
    "    with tf.contrib.framework.arg_scope([fully_connected], weights_initializer=he_init, activation_fn=tf.nn.elu, \n",
    "                                        normalizer_fn=batch_norm, normalizer_params=bn_params):\n",
    "        h1 = dropout(fully_connected(X_drop, 100, scope='h1'))\n",
    "        h2 = dropout(fully_connected(h1, 100, scope='h2'))\n",
    "        h3 = dropout(fully_connected(h2, 100, scope='h3'))\n",
    "        h4 = dropout(fully_connected(h3, 100, scope='h4'))\n",
    "        h5 = dropout(fully_connected(h4, 100, scope='h5'))\n",
    "        output = fully_connected(h5, 5, scope='output', activation_fn=None)\n",
    "\n",
    "# Loss from Network\n",
    "with tf.name_scope('loss'):\n",
    "    x_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=output)\n",
    "    loss = tf.reduce_mean(x_entropy, name='loss')\n",
    "\n",
    "# SGD\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train = optimizer.minimize(loss)\n",
    "    \n",
    "# Evaluation of performance\n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(output, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21735746\n",
      "0.9706169\n",
      "0.9768437\n",
      "0.9797626\n",
      "0.97898424\n",
      "0.9797626\n",
      "0.98287606\n",
      "0.9820977\n",
      "0.98112476\n",
      "0.98248684\n",
      "0.9830706\n",
      "0.97995716\n",
      "0.9822923\n",
      "0.97995716\n",
      "0.98112476\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "# Mini batches\n",
    "batches = mini_batches(x_train, y_train, 1000)\n",
    "max_acc = 0\n",
    "epochs = 0\n",
    "\n",
    "# Save model\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Log files\n",
    "import os\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
    "log_dir = os.path.join(os.getcwd(), 'tensorflow/logs/11-deep-learning-{}/'.format(now))\n",
    "acc_summary = tf.summary.scalar('accuracy',accuracy)\n",
    "writer = tf.summary.FileWriter(log_dir, tf.get_default_graph())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    # SGD Updates\n",
    "    for index, batch in enumerate(range(50000)):\n",
    "        batch_x, batch_y = batches.next_batch()\n",
    "        sess.run(train, feed_dict={X: batch_x, y:batch_y, is_training:True})\n",
    "        \n",
    "        # Early stopping and Checkpoint logging\n",
    "        if index % 1000 == 0:\n",
    "            saver.save(sess, os.path.join(os.getcwd(), 'tensorflow/models/11_deep_learning.ckpt'))\n",
    "            log_str = acc_summary.eval(feed_dict={X: x_test, y:y_test, is_training:False})\n",
    "            writer.add_summary(log_str, index)\n",
    "            \n",
    "            cur_acc = accuracy.eval(feed_dict={X: x_test, y:y_test, is_training:False})\n",
    "            print(cur_acc)\n",
    "            if cur_acc > max_acc:\n",
    "                max_acc = cur_acc\n",
    "                epochs = 0\n",
    "            else:\n",
    "                epochs = epochs + 1\n",
    "                if epochs > 3:\n",
    "                    saver.save(sess, os.path.join(os.getcwd(), 'tensorflow/models/11_deep_learning.ckpt'))\n",
    "                    break\n",
    "\n",
    "    # Save final model\n",
    "    saver.save(sess, os.path.join(os.getcwd(), 'tensorflow/models/11_deep_learning.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
