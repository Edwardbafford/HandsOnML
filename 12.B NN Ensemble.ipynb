{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Ensemble\n",
    "Re-use the three trained networks from 12.A to create an ensemble of nueral networks, with each one running on a different task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train, y_train = x_train, y_train\n",
    "x_test, y_test = x_test, y_test\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train, x_test = x_train.reshape(-1,28*28), x_test.reshape(-1,28*28)\n",
    "\n",
    "data = (x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create method for getting batches for training\n",
    "\n",
    "class mini_batches:\n",
    "    \n",
    "    def __init__(self, x, y, size):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.size = size\n",
    "        self.index = 0\n",
    "    \n",
    "    def next_batch(self):\n",
    "        if self.index + self.size >= len(self.x):            \n",
    "            batch_x = self.x[self.index:]\n",
    "            batch_y = self.y[self.index:]\n",
    "            self.index = 0\n",
    "            return batch_x, batch_y\n",
    "        \n",
    "        batch_x = self.x[self.index:self.index + self.size]\n",
    "        batch_y = self.y[self.index:self.index + self.size]\n",
    "        self.index = self.index + self.size\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster\n",
    "Only run once!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\"localhost:2222\", \"localhost:2223\",\"localhost:2224\"]\n",
    "jobs = {\"local\": tasks}\n",
    "cluster = tf.train.ClusterSpec(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "server1 = tf.train.Server(cluster, job_name=\"local\", task_index=0)\n",
    "server2 = tf.train.Server(cluster, job_name=\"local\", task_index=1)\n",
    "server3 = tf.train.Server(cluster, job_name=\"local\", task_index=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_location_trace(sess, op):\n",
    "    # From https://stackoverflow.com/a/41525764/7832197\n",
    "    run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "    run_metadata = tf.RunMetadata()\n",
    "    sess.run(op, options=run_options, run_metadata=run_metadata)\n",
    "    for device in run_metadata.step_stats.dev_stats:\n",
    "      print(device.device)\n",
    "      for node in device.node_stats:\n",
    "        print(\"  \", node.node_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected \n",
    "from tensorflow.contrib.layers import batch_norm\n",
    "from tensorflow.contrib.layers import dropout\n",
    "\n",
    "\n",
    "# Create graph with all three NNs built in, feed to a single output!\n",
    "        \n",
    "is_training = tf.placeholder(tf.bool, shape=(), name='is_training')\n",
    "    \n",
    "# Inputs for training\n",
    "X = tf.placeholder(tf.float32, shape=(None,28*28), name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')\n",
    "X_drop = dropout(X,.5, is_training=is_training)\n",
    "    \n",
    "# Nueral Network layers\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "bn_params = {'is_training':is_training, 'decay':0.99, 'updates_collections':None}\n",
    "    \n",
    "with tf.contrib.framework.arg_scope([fully_connected], weights_initializer=he_init, activation_fn=tf.nn.elu, \n",
    "                                            normalizer_fn=batch_norm, normalizer_params=bn_params):\n",
    "    \n",
    "    with tf.device(\"/job:local/task:0\"):\n",
    "        h1_0 = dropout(fully_connected(X_drop, 40, scope='h1_0'))\n",
    "        h2_0 = dropout(fully_connected(h1_0, 30, scope='h2_0'))\n",
    "        h3_0 = dropout(fully_connected(h2_0, 20, scope='h3_0'))\n",
    "        output_0 = fully_connected(h3_0, 10, scope='output_0', activation_fn=None)\n",
    "        \n",
    "    with tf.device(\"/job:local/task:1\"):\n",
    "        h1_1 = dropout(fully_connected(X_drop, 40, scope='h1_1'))\n",
    "        h2_1 = dropout(fully_connected(h1_1, 30, scope='h2_1'))\n",
    "        h3_1 = dropout(fully_connected(h2_1, 20, scope='h3_1'))\n",
    "        output_1 = fully_connected(h3_1, 10, scope='output_1', activation_fn=None)\n",
    "    \n",
    "    with tf.device(\"/job:local/task:2\"):\n",
    "        h1_2 = dropout(fully_connected(X_drop, 40, scope='h1_2'))\n",
    "        h2_2 = dropout(fully_connected(h1_2, 30, scope='h2_2'))\n",
    "        h3_2 = dropout(fully_connected(h2_2, 20, scope='h3_2'))\n",
    "        output_2 = fully_connected(h3_2, 10, scope='output_2', activation_fn=None)\n",
    "    \n",
    "# Evaluation of performance\n",
    "output = tf.add_n([output_0,output_1,output_2])\n",
    "correct = tf.nn.in_top_k(output, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess1 = tf.Session(server1.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_list = []\n",
    "value_list.extend(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='h[123]_[012]'))\n",
    "og_saver = tf.train.Saver(value_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate and restore model\n",
    "\n",
    "sess1.run(tf.global_variables_initializer())\n",
    "og_saver.restore(sess1,'./tensorflow/models/12_deep_learning_parallel.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tensorflow/models/12_deep_learning_parallel.ckpt\n",
      "0.1274\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy of the model\n",
    "\n",
    "print(sess1.run(accuracy,feed_dict={X:data[2], y:data[3], is_training:False}, options=run_options, run_metadata=run_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
