{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training in 'Parallel'\n",
    "Here we train multiple models with varying hyperparameters. We design the client to be able to distribute runs onto various servers/devices. First we setup a cluster running on three different processes -- in a production situation these would ideally be on different computers to speed up the training process. Next, we create three NNs each one pinned on a seperate task. Finally we train those three NNs -- again in a production environment those NNs would be trained in parallel!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips:\n",
    "* Pin sessions to tasks on the cluster\n",
    "* Restart a graph -> restart all active sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train, y_train = x_train, y_train\n",
    "x_test, y_test = x_test, y_test\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train, x_test = x_train.reshape(-1,28*28), x_test.reshape(-1,28*28)\n",
    "\n",
    "data = (x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create method for getting batches for training\n",
    "\n",
    "class mini_batches:\n",
    "    \n",
    "    def __init__(self, x, y, size):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.size = size\n",
    "        self.index = 0\n",
    "    \n",
    "    def next_batch(self):\n",
    "        if self.index + self.size >= len(self.x):            \n",
    "            batch_x = self.x[self.index:]\n",
    "            batch_y = self.y[self.index:]\n",
    "            self.index = 0\n",
    "            return batch_x, batch_y\n",
    "        \n",
    "        batch_x = self.x[self.index:self.index + self.size]\n",
    "        batch_y = self.y[self.index:self.index + self.size]\n",
    "        self.index = self.index + self.size\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster\n",
    "Only run once!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\"localhost:2222\", \"localhost:2223\",\"localhost:2224\"]\n",
    "jobs = {\"local\": tasks}\n",
    "cluster = tf.train.ClusterSpec(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "server1 = tf.train.Server(cluster, job_name=\"local\", task_index=0)\n",
    "server2 = tf.train.Server(cluster, job_name=\"local\", task_index=1)\n",
    "server3 = tf.train.Server(cluster, job_name=\"local\", task_index=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_location_trace(sess, op):\n",
    "    # From https://stackoverflow.com/a/41525764/7832197\n",
    "    run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "    run_metadata = tf.RunMetadata()\n",
    "    sess.run(op, options=run_options, run_metadata=run_metadata)\n",
    "    for device in run_metadata.step_stats.dev_stats:\n",
    "      print(device.device)\n",
    "      for node in device.node_stats:\n",
    "        print(\"  \", node.node_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected \n",
    "from tensorflow.contrib.layers import batch_norm\n",
    "from tensorflow.contrib.layers import dropout\n",
    "\n",
    "def make_network(task,name):\n",
    "    with tf.device(\"/job:local/task:{0}\".format(task)):\n",
    "        \n",
    "        is_training = tf.placeholder(tf.bool, shape=(), name='is_training_{0}'.format(name))\n",
    "    \n",
    "        # Inputs for training\n",
    "        X = tf.placeholder(tf.float32, shape=(None,28*28), name='X_{0}'.format(name))\n",
    "        y = tf.placeholder(tf.int32, shape=(None), name='y_{0}'.format(name))\n",
    "        X_drop = dropout(X,.5, is_training=is_training)\n",
    "    \n",
    "        # Nueral Network layers\n",
    "        he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "        bn_params = {'is_training':is_training, 'decay':0.99, 'updates_collections':None}\n",
    "    \n",
    "        with tf.contrib.framework.arg_scope([fully_connected], weights_initializer=he_init, activation_fn=tf.nn.elu, \n",
    "                                                    normalizer_fn=batch_norm, normalizer_params=bn_params):\n",
    "            h1 = dropout(fully_connected(X_drop, 40, scope='h1_{0}'.format(name)))\n",
    "            h2 = dropout(fully_connected(h1, 30, scope='h2_{0}'.format(name)))\n",
    "            h3 = dropout(fully_connected(h2, 20, scope='h3_{0}'.format(name)))\n",
    "            output = fully_connected(h3, 10, scope='output_{0}'.format(name), activation_fn=None)\n",
    "        \n",
    "        # Loss from Network\n",
    "        x_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=output)\n",
    "        loss = tf.reduce_mean(x_entropy, name='loss_{0}'.format(name))\n",
    "    \n",
    "        # SGD\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        train = optimizer.minimize(loss)\n",
    "    \n",
    "        # Evaluation of performance\n",
    "        correct = tf.nn.in_top_k(output, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        \n",
    "    return train, accuracy, X, y, is_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0, a0, X0, y0, b0 = make_network(\"0\",\"0\")\n",
    "t1, a1, X1, y1, b1 = make_network(\"1\",\"1\")\n",
    "t2, a2, X2, y2, b2 = make_network(\"2\",\"2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess1 = tf.Session(server1.target)\n",
    "sess2 = tf.Session(server2.target)\n",
    "sess3 = tf.Session(server3.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess1.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "\n",
    "def train_model(sess, train, accuracy, X, y, is_training, data):\n",
    "\n",
    "    # Mini batches\n",
    "    batches = mini_batches(data[0], data[1], 500)\n",
    "    max_acc = 0\n",
    "    epochs = 0\n",
    "\n",
    "    # Save model\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # SGD Updates\n",
    "    for index, batch in enumerate(range(50000)):\n",
    "        batch_x, batch_y = batches.next_batch()\n",
    "        sess.run(train, feed_dict={X: batch_x, y:batch_y, is_training:True})\n",
    "        \n",
    "        # Early stopping and Checkpoint logging\n",
    "        if index % 500 == 0:\n",
    "            saver.save(sess, os.path.join(os.getcwd(), 'tensorflow/models/12_deep_learning_parallel.ckpt'))\n",
    "            \n",
    "            cur_acc = sess.run(accuracy,feed_dict={X:data[2], y:data[3], is_training:False})\n",
    "            print(cur_acc)\n",
    "            if cur_acc > max_acc:\n",
    "                max_acc = cur_acc\n",
    "                epochs = 0\n",
    "            else:\n",
    "                epochs = epochs + 1\n",
    "                if epochs > 3:\n",
    "                    saver.save(sess, os.path.join(os.getcwd(), 'tensorflow/models/12_deep_learning_parallel.ckpt'))\n",
    "                    break\n",
    "\n",
    "    # Save final model\n",
    "    saver.save(sess, os.path.join(os.getcwd(), 'tensorflow/models/12_deep_learning_parallel.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0973\n",
      "0.6499\n",
      "0.7187\n",
      "0.7352\n",
      "0.7529\n",
      "0.755\n",
      "0.7636\n",
      "0.7722\n",
      "0.7752\n",
      "0.7721\n",
      "0.7656\n",
      "0.772\n",
      "0.7675\n"
     ]
    }
   ],
   "source": [
    "train_model(sess1, t0, a0, X0, y0, b0, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1039\n",
      "0.657\n",
      "0.7145\n",
      "0.7438\n",
      "0.7468\n",
      "0.7634\n",
      "0.7575\n",
      "0.7639\n",
      "0.7662\n",
      "0.7771\n",
      "0.7742\n",
      "0.771\n",
      "0.7748\n",
      "0.7769\n"
     ]
    }
   ],
   "source": [
    "train_model(sess2, t1, a1, X1, y1, b1, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1074\n",
      "0.6504\n",
      "0.7105\n",
      "0.7296\n",
      "0.7513\n",
      "0.757\n",
      "0.7635\n",
      "0.762\n",
      "0.771\n",
      "0.7713\n",
      "0.7768\n",
      "0.7736\n",
      "0.7763\n",
      "0.7757\n",
      "0.7813\n",
      "0.7804\n",
      "0.7752\n",
      "0.777\n",
      "0.7767\n"
     ]
    }
   ],
   "source": [
    "train_model(sess3, t2, a2, X2, y2, b2, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess1.close()\n",
    "sess2.close()\n",
    "sess3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
