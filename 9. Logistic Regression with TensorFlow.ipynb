{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression implementation using TensorFlow\n",
    "Use the TF framework to implement a Gradient Descent Logistic Regression algorithm!! We try utilizing the standard features TensorFlow offers such as saving the model and logging progress for tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# Get data\n",
    "\n",
    "X, y = make_moons()\n",
    "\n",
    "rows,cols = X.shape\n",
    "X_1 = np.c_[np.ones((rows,1)), X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Logisitc Regression class imlemented fully in TensorFlow obviously missing some standard functionality...\n",
    "# but fitting logic has been fully implemented\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "class LogisticReg_TF():\n",
    "    \n",
    "    # Creates computational graph\n",
    "    def __init__(self, learning_rate=0.01):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.data = tf.placeholder(tf.float32, shape=(None,(cols+1)), name='data')\n",
    "        self.classes = tf.placeholder(tf.float32, shape=(None,1), name='classes')\n",
    "        self.theta = tf.Variable(tf.random_uniform([cols + 1,1],-1,1), name='theta')\n",
    "        \n",
    "        # y = 1/(1 + e^-(w * X))\n",
    "        self.pred = tf.divide(tf.constant(1.0,dtype=tf.float32),\n",
    "                        tf.math.add(\n",
    "                            tf.constant(1.0,dtype=tf.float32),\n",
    "                            tf.math.exp(tf.multiply(\n",
    "                                tf.constant(-1.0,dtype=tf.float32),\n",
    "                                tf.matmul(self.data,self.theta)))\n",
    "                        ), name='pred')\n",
    "        \n",
    "        # loss = -(y * log(pred) + (1-y) * log(pred))\n",
    "        self.loss = tf.multiply(\n",
    "                        tf.constant(-1.0,dtype=tf.float32),\n",
    "                        tf.math.add(\n",
    "                            tf.matmul(tf.transpose(self.classes),\n",
    "                                      tf.math.log(self.pred)),\n",
    "                            tf.matmul(tf.transpose(tf.subtract(tf.constant(1.0,dtype=tf.float32),self.classes)),\n",
    "                                      tf.math.log(self.pred))\n",
    "                        ), name='loss')\n",
    "        \n",
    "        # gradient descent update to theta \n",
    "        self.train = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(self.loss, var_list=[self.theta])\n",
    "    \n",
    "    \n",
    "    # Entire fit process\n",
    "    def fit(self, X, y, n_epochs):\n",
    "        \n",
    "        # Logging tools\n",
    "        now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
    "        log_dir = os.path.join(os.getcwd(), 'tensorflow/logs/run-{}/'.format(now))\n",
    "        \n",
    "        loss_summary = tf.summary.scalar('Log Loss',tf.squeeze(self.loss))\n",
    "        writer = tf.summary.FileWriter(log_dir, tf.get_default_graph())\n",
    "        \n",
    "        # Creating session\n",
    "        init = tf.global_variables_initializer()\n",
    "        ss = tf.InteractiveSession()\n",
    "        ss.run(init)\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        # GD update\n",
    "        for epoch in range(n_epochs):\n",
    "            ss.run(log.train, feed_dict={log.data:np.reshape(X,(-1,3)),log.classes:np.reshape(y,(-1,1))})\n",
    "    \n",
    "            # Log updates\n",
    "            if epoch % 5 == 0:\n",
    "                saver.save(ss, os.path.join(os.getcwd(), 'tensorflow/models/log_reg.ckpt'))\n",
    "                log_str = loss_summary.eval(feed_dict={self.data:np.reshape(X_1,(-1,3)),self.classes:np.reshape(y,(-1,1))})\n",
    "                writer.add_summary(log_str, epoch)\n",
    "    \n",
    "        ss.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name Log Loss is illegal; using Log_Loss instead.\n"
     ]
    }
   ],
   "source": [
    "# Run it!\n",
    "\n",
    "log = LogisticReg_TF(0.01)\n",
    "log.fit(X_1, y, 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
